{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links=pd.read_csv('Data/links.csv')\n",
    "df_movies=pd.read_csv('Data/movies.csv')\n",
    "df_ratings=pd.read_csv('Data/ratings.csv')\n",
    "df_tags=pd.read_csv('Data/tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the links dataset\n",
    "df_links.head()  # show first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_links.info())          # Get info on data types and non-null counts\n",
    "print(df_links.describe())     # Summary statistics for numerical columns\n",
    "print(df_links.isnull().sum())  # Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the movies dataset\n",
    "df_movies.head()  # show first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_movies.info())          # Get info on data types and non-null counts\n",
    "print(df_movies.describe())     # Summary statistics for numerical columns\n",
    "print(df_movies.isnull().sum())  # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the ratings dataset\n",
    "df_ratings.head()  # show first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ratings.info())         # Get info on data types and non-null counts\n",
    "print(df_ratings.describe())     # Summary statistics for numerical columns\n",
    "print(df_ratings.isnull().sum()) # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the tags dataset\n",
    "df_tags.head()  # show first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tags.info())         # Get info on data types and non-null counts\n",
    "print(df_tags.describe())     # Summary statistics for numerical columns\n",
    "print(df_tags.isnull().sum()) # Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links = df_links.dropna() # drop missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.isnull().sum() #check the missing data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates in links.csv\n",
    "df_links.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates in movies.csv\n",
    "df_movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates in ratings.csv\n",
    "df_ratings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates in tags.csv\n",
    "df_tags.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data to correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings['timestamp'] = pd.to_datetime(df_ratings['timestamp'])    # Convert to datetime\n",
    "df_tags['timestamp'] = pd.to_datetime(df_tags['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate the Z-scores for the column\n",
    "z_scores = np.abs(stats.zscore(df_ratings['rating']))\n",
    "\n",
    "# Set a threshold for identifying outliers\n",
    "threshold = 3\n",
    "\n",
    "# Find rows where Z-score is greater than the threshold\n",
    "outliers = df_ratings[z_scores > threshold]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No outliers detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with Movies.csv genre column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['genres'] = df_movies['genres'].str.split('|')\n",
    "df_exploded_movies = df_movies.explode('genres')\n",
    "df_exploded_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to create a one-hot encoded DataFrame for genres\n",
    "genres_encoding = df_exploded_movies.pivot_table(index='movieId', columns='genres', aggfunc=lambda x: 1, fill_value=0)\n",
    "\n",
    "# Flatten the multi-level column index resulting from pivot to get simple column names\n",
    "genres_encoding.columns = genres_encoding.columns.get_level_values(1)\n",
    "genres_encoding = genres_encoding.add_prefix('genre_')\n",
    "\n",
    "# Merge the one-hot encoded genres with the original movies DataFrame \n",
    "df_movies_encoded = pd.merge(df_movies.drop(columns='genres').drop_duplicates(), genres_encoding, on='movieId', how='left')\n",
    "\n",
    "df_movies_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_movies_merged= pd.merge(df_movies_encoded, df_ratings, on='movieId', how='inner') # merge ratings.csv with movies.csv\n",
    "df_ratings_movies_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=pd.merge(df_ratings_movies_merged, df_tags, on=['movieId', 'userId'], how='left')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with the NaN values in tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary indicator column for the presence of tags\n",
    "df_merged['tag_present'] = df_merged['tag'].notna().astype(int)\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Refine the User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = df_merged.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "user_item_matrix_filled = user_item_matrix.fillna(0)\n",
    "user_item_matrix_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import svds\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "\n",
    "# Convert the user-item matrix to a sparse matrix format and ensure data is float\n",
    "user_item_matrix_sparse = sparse.csr_matrix(user_item_matrix_filled.values.astype(float))\n",
    "\n",
    "# Apply SVD on the sparse matrix\n",
    "U, sigma, Vt = svds(user_item_matrix_sparse, k=50)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruct the predicted ratings matrix\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "# Convert back to DataFrame for further analysis\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# Print the predicted ratings to verify\n",
    "print(predicted_ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_ratings['rating'], bins=10, kde=True)\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_rated = df_ratings.groupby('movieId').size().nlargest(10)\n",
    "most_rated_movies = df_movies[df_movies['movieId'].isin(most_rated.index)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='title', y=most_rated.values, data=most_rated_movies)\n",
    "plt.title('Top 10 Most Rated Movies')\n",
    "plt.xlabel('Movie Title')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_genre_ratings = df_exploded_movies.merge(df_ratings, on='movieId').groupby('genres')['rating'].mean().sort_values()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "avg_genre_ratings.plot(kind='bar')\n",
    "plt.title('Average Rating by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count_by_user = df_ratings['userId'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(ratings_count_by_user, bins=30, kde=True)\n",
    "plt.title('Distribution of Ratings Count by User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Recommendation Model with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Prepare user-item matrix with NaNs filled with 0 for k-NN\n",
    "user_item_matrix_filled = user_item_matrix.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neighbors\n",
    "k = 5\n",
    "\n",
    "# Initialize KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=k, metric='cosine')\n",
    "\n",
    "# Fit the model on the user-item matrix\n",
    "# Fit the k-NN model on user-item matrix\n",
    "knn = KNeighborsRegressor(n_neighbors=k, metric='cosine')\n",
    "knn.fit(user_item_matrix_filled.values, user_item_matrix_filled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies_knn(user_id, user_item_matrix_filled, movies_df, knn_model, num_recommendations=5):\n",
    "    # Retrieve the ratings for the specified user\n",
    "    user_vector = user_item_matrix_filled.loc[user_id].values.reshape(1, -1)\n",
    "    \n",
    "    # Find the k-nearest neighbors\n",
    "    distances, indices = knn_model.kneighbors(user_vector)\n",
    "    \n",
    "    # Calculate the mean rating for all movies based on neighbors\n",
    "    similar_users = user_item_matrix_filled.iloc[indices.flatten()]\n",
    "    mean_ratings = similar_users.mean(axis=0)\n",
    "    \n",
    "    # Filter out movies already rated by the user\n",
    "    unrated_movies = user_item_matrix_filled.loc[user_id].isna()\n",
    "    recommendations = mean_ratings[unrated_movies].sort_values(ascending=False).head(num_recommendations)\n",
    "    \n",
    "    # Return the movie titles for the top recommendations\n",
    "    return movies_df[movies_df['movieId'].isin(recommendations.index)][['movieId', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 2  # Replace with any user ID from your dataset\n",
    "recommendations = recommend_movies_knn(user_id, user_item_matrix_filled, df_movies, knn, num_recommendations=5)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Model\n",
    "Lets use regression metrics like RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the NaNs for comparison\n",
    "predicted_ratings_filled = predicted_ratings_df[user_item_matrix.notna()]\n",
    "actual_ratings = user_item_matrix[user_item_matrix.notna()]\n",
    "\n",
    "actual_ratings_no_nan = actual_ratings.dropna()\n",
    "predicted_ratings_no_nan = predicted_ratings_filled.dropna()\n",
    "\n",
    "# If dropping leads to mismatched indices, align the matrices before evaluating\n",
    "actual_ratings_aligned, predicted_ratings_aligned = actual_ratings_no_nan.align(predicted_ratings_no_nan, join='inner', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_ratings_aligned.shape)\n",
    "print(predicted_ratings_aligned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Alignment\n",
    "actual_ratings_no_nan, predicted_ratings_no_nan = actual_ratings.align(predicted_ratings_filled, join='inner', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of dropping NaNs, fill them with a specific value\n",
    "actual_ratings_filled = actual_ratings.fillna(0)\n",
    "predicted_ratings_filled = predicted_ratings_filled.fillna(0)\n",
    "\n",
    "actual_ratings_aligned, predicted_ratings_aligned = actual_ratings_filled.align(predicted_ratings_filled, join='inner', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Optionally fill NaNs (or handle as per project context)\n",
    "actual_ratings_filled = actual_ratings.fillna(0)\n",
    "predicted_ratings_filled = predicted_ratings_filled.fillna(0)\n",
    "\n",
    "# Align the dataframes and check shape\n",
    "actual_ratings_aligned, predicted_ratings_aligned = actual_ratings_filled.align(predicted_ratings_filled, join='inner', axis=0)\n",
    "print(actual_ratings_aligned.shape, predicted_ratings_aligned.shape)\n",
    "\n",
    "# Calculate RMSE and MAE only if the DataFrames are non-empty\n",
    "if actual_ratings_aligned.shape[0] > 0:\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings_aligned, predicted_ratings_aligned))\n",
    "    mae = mean_absolute_error(actual_ratings_aligned, predicted_ratings_aligned)\n",
    "    \n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "else:\n",
    "    print(\"Error: No overlapping ratings between actual and predicted data. Ensure proper alignment or handling of missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 5  # Replace with any user ID from your dataset\n",
    "recommendations = recommend_movies(predicted_ratings_df, user_id, df_movies, num_recommendations=5)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
